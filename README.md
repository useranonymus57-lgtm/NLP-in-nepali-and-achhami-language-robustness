# Dialectal Robustness of Nepali NLP Systems: NER and POS Tagging on the Achhami Dialect

> The first systematic benchmark evaluating Named Entity Recognition (NER) and Part-of-Speech (POS) tagging performance degradation from Standard Nepali to the Achhami dialect.

---

## ğŸ“Œ Overview

This repository contains the dataset, annotation guidelines, evaluation scripts, and results for our study on dialectal robustness in Nepali NLP systems. We benchmark **5 NER models** and **4 POS tagging models** on a parallel corpus of **300 sentences** in both Standard Nepali and the Achhami dialect of the Far-Western region of Nepal.

---

## ğŸ“‚ Repository Structure
ner_model/
â”œâ”€â”€ dialect_dataset.csv
â”‚
â”œâ”€â”€ NER_BERT/
â”‚   â”œâ”€â”€ Achhami_both.ipynb
â”‚   â”œâ”€â”€ ner_nepaliNEPBERT.ipynb
â”‚   â””â”€â”€ ner_nepalimbert.ipynb
â”‚
â””â”€â”€ NER_LLM/
    â”œâ”€â”€ achhami_results_anthropic_...
    â”œâ”€â”€ achhami_results_meta-llama...
    â”œâ”€â”€ achhami_results_openai_gp...
    â”œâ”€â”€ complete_ner.py
    â”œâ”€â”€ comprehensive_model_com...
    â”œâ”€â”€ confusion_matrix__achha...
    â”œâ”€â”€ confusion_matrix__achha...
    â”œâ”€â”€ confusion_matrix__achha...
    â”œâ”€â”€ confusion_matrix__standar...
    â”œâ”€â”€ confusion_matrix__standar...
    â”œâ”€â”€ confusion_matrix__standar...
    â”œâ”€â”€ load_csv.py
    â”œâ”€â”€ multi_model_comparison.png
    â”œâ”€â”€ nepali_results_anthropic_cla...
    â”œâ”€â”€ nepali_results_meta-llama_ll...
    â”œâ”€â”€ nepali_results_openai_gpt-4...
    â”œâ”€â”€ nercsv
    â”œâ”€â”€ ner_achami - Sheet1.csv
    â””â”€â”€ performance_degradation_...
    
pos/
â”œâ”€â”€ ack_dataset_clean.csv
â”œâ”€â”€ achham_dataset.csv
â”œâ”€â”€ nep_dataset_clean.csv
â”œâ”€â”€ nepali_dataset.csv
â”œâ”€â”€ nepali_pos.ipynb
â”œâ”€â”€ nepali_pos_llm_eval.py
â”‚
â””â”€â”€ pos_results/
    â”œâ”€â”€ checkpoint_Claude_3_5_Ha...
    â”œâ”€â”€ checkpoint_Claude_3_5_Ha...
    â”œâ”€â”€ checkpoint_GPT_4o_Mini_A...
    â”œâ”€â”€ checkpoint_GPT_4o_Mini_A...
    â”œâ”€â”€ checkpoint_Llama_3_1_70...
    â”œâ”€â”€ checkpoint_Llama_3_1_70...
    â”‚
    â”œâ”€â”€ confusion_Claude_3_5_Ha...
    â”œâ”€â”€ confusion_Claude_3_5_Ha...
    â”œâ”€â”€ confusion_GPT_4o_Mini_A...
    â”œâ”€â”€ confusion_GPT_4o_Mini_A...
    â”œâ”€â”€ confusion_Llama_3_1_70...
    â”œâ”€â”€ confusion_Llama_3_1_70...
    â”‚
    â”œâ”€â”€ f1_heatmap_all.png
    â”œâ”€â”€ multi_model_comparison...
    â”‚
    â”œâ”€â”€ per_tag_f1_Claude_3_5_Ha...
    â”œâ”€â”€ per_tag_f1_Claude_3_5_Ha...
    â”œâ”€â”€ per_tag_f1_GPT_4o_Mini_A...
    â”œâ”€â”€ per_tag_f1_GPT_4o_Mini_A...
    â”œâ”€â”€ per_tag_f1_Llama_3_1_70...
    â”œâ”€â”€ per_tag_f1_Llama_3_1_70...
    â”‚
    â”œâ”€â”€ performance_degradation...
    â”œâ”€â”€ report.txt
    â”‚
    â”œâ”€â”€ results_Claude_3_5_Haku...
    â”œâ”€â”€ results_Claude_3_5_Haku...
    â”œâ”€â”€ results_GPT_4o_Mini_Nepa...
    â”œâ”€â”€ results_GPT_4o_Mini_Nepa...
    â”œâ”€â”€ results_Llama_3_1_70B_Ne...
    â”œâ”€â”€ results_Llama_3_1_70B_Nep...
    â””â”€â”€ results_summary.csv

---

## ğŸ“Š Dataset

| Property | Details |
|---|---|
| Sentences | 300 parallel sentences |
| Dialects | Standard Nepali, Achhami |
| NER Tags | PER, ORG, LOC, DATE, MISC |
| POS Tags | Universal Dependencies (17 tags) |

---

## ğŸ¤– Models Evaluated

### NER Models
| Model | Type |
|---|---|
| NepBERTa | Monolingual BERT |
| mBERT-Nepali | Multilingual BERT |
| Claude 3.5 Haiku | LLM |
| GPT-4o Mini | LLM |
| Llama 3.1 70B | LLM |

### POS Tagging Models
| Model | Type |
|---|---|
| XLM-RoBERTa UD | Fine-tuned Transformer |
| Claude 3.5 Haiku | LLM |
| GPT-4o Mini | LLM |
| Llama 3.1 70B | LLM |

---

## ğŸ“ˆ Key Results

### NER â€” Precision, Recall, F1

| Model | Dialect | Precision | Recall | F1 |
|---|---|---|---|---|
| NepBERTa | Nepali | 0.685 | 0.605 | 0.642 |
| NepBERTa | Achhami | 0.652 | 0.584 | 0.616 |
| mBERT-Nepali | Nepali | 0.743 | 0.605 | 0.667 |
| mBERT-Nepali | Achhami | 0.695 | 0.571 | 0.627 |
| Claude 3.5 Haiku | Nepali | 0.881 | 0.901 | 0.891 |
| Claude 3.5 Haiku | Achhami | 0.856 | 0.884 | 0.870 |
| GPT-4o Mini | Nepali | 0.888 | 0.838 | 0.862 |
| GPT-4o Mini | Achhami | 0.839 | 0.815 | 0.827 |
| Llama 3.1 70B | Nepali | 0.860 | 0.811 | 0.835 |
| Llama 3.1 70B | Achhami | 0.832 | 0.788 | 0.810 |

### POS Tagging â€” Accuracy, Precision, Recall, F1

| Model | Dialect | Accuracy | Precision | Recall | F1 |
|---|---|---|---|---|---|
| XLM-RoBERTa UD | Nepali | 0.790 | 0.653 | 0.682 | 0.642 |
| XLM-RoBERTa UD | Achhami | 0.726 | 0.511 | 0.517 | 0.497 |
| Claude 3.5 Haiku | Nepali | 0.909 | 0.759 | 0.809 | 0.751 |
| Claude 3.5 Haiku | Achhami | 0.904 | 0.720 | 0.735 | 0.722 |
| GPT-4o Mini | Nepali | 0.848 | 0.796 | 0.788 | 0.771 |
| GPT-4o Mini | Achhami | 0.874 | 0.701 | 0.711 | 0.701 |
| Llama 3.1 70B | Nepali | 0.818 | 0.581 | 0.636 | 0.570 |
| Llama 3.1 70B | Achhami | 0.766 | 0.552 | 0.514 | 0.518 |

---

## ğŸ”‘ Key Findings

- **Standard Nepali bias is confirmed** across all models and both tasks
- **POS tagging degrades more severely** (2.91%â€“14.49%) than NER (2.12%â€“3.97%)
- **Claude 3.5 Haiku** is the most robust model across both tasks
- **NepBERTa** outperforms multilingual mBERT in dialectal robustness despite being monolingual
- **XLM-RoBERTa UD** suffers the largest degradation (14.49% Macro F1 drop) across all models
- Multilingual pre-training **does not inherently** confer dialectal robustness

---



## âš ï¸ Ethical Considerations

Our datasets were constructed from publicly accessible news articles. No private or sensitive user data were collected. Personal identifiers beyond named entities required for the NER task were removed during annotation. POS annotation was performed solely on linguistic structure and contains no personally identifiable information. Both datasets are intended solely for research and educational purposes. We acknowledge that automated NLP evaluation on dialectal text carries the risk of reinforcing existing biases against underrepresented linguistic communities if findings are not interpreted with appropriate cultural and sociolinguistic context.
