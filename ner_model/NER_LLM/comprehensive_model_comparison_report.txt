================================================================================
COMPREHENSIVE NEPALI NER DIALECTAL ROBUSTNESS EVALUATION
Comparing Multiple Models
================================================================================

================================================================================
MODEL: openai/gpt-4o-mini
================================================================================

STANDARD NEPALI RESULTS
--------------------------------------------------------------------------------
Accuracy:  0.7576 (75.76%)
Precision: 0.8879 (88.79%)
Recall:    0.8377 (83.77%)
F1-Score:  0.8621 (86.21%)
TP: 475, FP: 60, FN: 92

ACHHAMI DIALECT RESULTS
--------------------------------------------------------------------------------
Accuracy:  0.7043 (70.43%)
Precision: 0.8385 (83.85%)
Recall:    0.8148 (81.48%)
F1-Score:  0.8265 (82.65%)
TP: 462, FP: 89, FN: 105

PERFORMANCE DEGRADATION
--------------------------------------------------------------------------------
Accuracy Decrease:  +5.33%
Precision Decrease: +4.94%
Recall Decrease:    +2.29%
F1-Score Decrease:  +3.56%

================================================================================
MODEL: anthropic/claude-3.5-haiku
================================================================================

STANDARD NEPALI RESULTS
--------------------------------------------------------------------------------
Accuracy:  0.8035 (80.35%)
Precision: 0.8810 (88.10%)
Recall:    0.9012 (90.12%)
F1-Score:  0.8910 (89.10%)
TP: 511, FP: 69, FN: 56

ACHHAMI DIALECT RESULTS
--------------------------------------------------------------------------------
Accuracy:  0.7696 (76.96%)
Precision: 0.8564 (85.64%)
Recall:    0.8836 (88.36%)
F1-Score:  0.8698 (86.98%)
TP: 501, FP: 84, FN: 66

PERFORMANCE DEGRADATION
--------------------------------------------------------------------------------
Accuracy Decrease:  +3.39%
Precision Decrease: +2.46%
Recall Decrease:    +1.76%
F1-Score Decrease:  +2.12%

================================================================================
MODEL: meta-llama/llama-3.1-70b-instruct
================================================================================

STANDARD NEPALI RESULTS
--------------------------------------------------------------------------------
Accuracy:  0.7165 (71.65%)
Precision: 0.8598 (85.98%)
Recall:    0.8113 (81.13%)
F1-Score:  0.8348 (83.48%)
TP: 460, FP: 75, FN: 107

ACHHAMI DIALECT RESULTS
--------------------------------------------------------------------------------
Accuracy:  0.6804 (68.04%)
Precision: 0.8324 (83.24%)
Recall:    0.7884 (78.84%)
F1-Score:  0.8098 (80.98%)
TP: 447, FP: 90, FN: 120

PERFORMANCE DEGRADATION
--------------------------------------------------------------------------------
Accuracy Decrease:  +3.61%
Precision Decrease: +2.74%
Recall Decrease:    +2.29%
F1-Score Decrease:  +2.51%

================================================================================
SUMMARY COMPARISON - STANDARD NEPALI
================================================================================
Model                                              Acc      Prec     Rec      F1      
--------------------------------------------------------------------------------
openai/gpt-4o-mini                                 0.7576  0.8879  0.8377  0.8621
anthropic/claude-3.5-haiku                         0.8035  0.8810  0.9012  0.8910
meta-llama/llama-3.1-70b-instruct                  0.7165  0.8598  0.8113  0.8348

================================================================================
SUMMARY COMPARISON - ACHHAMI DIALECT
================================================================================
Model                                              Acc      Prec     Rec      F1      
--------------------------------------------------------------------------------
openai/gpt-4o-mini                                 0.7043  0.8385  0.8148  0.8265
anthropic/claude-3.5-haiku                         0.7696  0.8564  0.8836  0.8698
meta-llama/llama-3.1-70b-instruct                  0.6804  0.8324  0.7884  0.8098
